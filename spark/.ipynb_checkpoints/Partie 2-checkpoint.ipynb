{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "# Introduction\n",
    "\n",
    "Le but de cette partie est d'entrainer un perceptron dont\n",
    "la fonction d'activation est une <u>fonction sigmoïde</u>.\n",
    "\n",
    "Nous utilisons pour cela Apache Spark avec le langage \n",
    "Scala.\n",
    "\n",
    "Le fichier de données `crimes_fromWf_withClusters_sparkReady` recense:\n",
    "\n",
    "- 7 catégories, dans l'ensemble $C = \\{0..6\\}$, donc $|C| = 7$,\n",
    "- 39 features (ou colonnes).\n",
    "\n",
    "Les features sont binaires, elles prennent donc des valeurs dans $\\mathbb{B} = \\{0, 1\\}$.\n",
    "\n",
    "Pour une ligne donnée du fichier (un échantillon) on obtient donc un features vector sous la forme $fv_i = (f_{i,1},\\   f_{i,2}, ...,\\ f_{i,j})$, où:\n",
    "\n",
    " - $fv$ est un feature vector,\n",
    " - $fv_i$ est un feature vector représentant l'échantillon $i$,\n",
    " - $f_j$ est la feature à la colonne $j$, $f_j \\in \\mathbb{B}$.\n",
    " \n",
    "Dans notre cas la cardinalité de tous les $fv_i$ est $|fv| = 39$. C'est-à-dire que tout les $fv_i$ ont le même nombre de features.\n",
    "\n",
    "Nous cherchons à établire, pour tout les $i$, à quelle catégorie correspond $fv_i$.\n",
    "Nous devont donc construire ou approximer une fonction de prédiction $p$ tel que $p(fv_i) \\rightarrow c$, où $c \\in C$.\n",
    "\n",
    "\n",
    "# Traitement\n",
    "\n",
    "## Imports des outils nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.util.MLUtils\n",
    "import org.apache.spark.sql.Dataset\n",
    "import org.apache.spark.sql.Row\n",
    "import org.apache.spark.ml.classification.MultilayerPerceptronClassifier\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  6.0|(39,[6,16,34],[1....|\n",
      "|  2.0|(39,[6,16,34],[1....|\n",
      "|  2.0|(39,[6,16,34],[1....|\n",
      "|  0.0|(39,[6,17,34],[1....|\n",
      "|  0.0|(39,[7,17,34],[1....|\n",
      "|  0.0|(39,[8,17,34],[1....|\n",
      "|  0.0|(39,[8,17,34],[1....|\n",
      "|  0.0|(39,[9,17,34],[1....|\n",
      "|  0.0|(39,[10,17,34],[1...|\n",
      "|  0.0|(39,[11,17,34],[1...|\n",
      "|  0.0|(39,[11,17,34],[1...|\n",
      "|  2.0|(39,[12,17,34],[1...|\n",
      "|  0.0|(39,[13,17,34],[1...|\n",
      "|  0.0|(39,[6,17,34],[1....|\n",
      "|  1.0|(39,[9,17,34],[1....|\n",
      "|  1.0|(39,[9,17,34],[1....|\n",
      "|  0.0|(39,[13,17,34],[1...|\n",
      "|  4.0|(39,[8,17,34],[1....|\n",
      "|  2.0|(39,[9,16,34],[1....|\n",
      "|  1.0|(39,[13,17,34],[1...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Import des données avec cluster\n",
    "// Le fichier `crimes_fromWf_withClusters_sparkReady.txt` à\n",
    "// été reformaté en un fichier `clu.txt` \n",
    "val cluData = spark.read.format(\"libsvm\").load(\"../data/clu-days.txt\")\n",
    "cluData.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Préparation des données\n",
    "\n",
    "On sépare les datasets en deux sous-ensembles:\n",
    "\n",
    "- Un pour l'entrainement ($70\\%$ des données),\n",
    "- Un pour le test ($30\\%$ de données)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "// 0.7 et 0.3 pour un séparation à 70/30\n",
    "// le paramètre `seed` sert ... de seed à la fonction random.\n",
    "val splits = cluData.randomSplit(Array(0.7, 0.3)) \n",
    "\n",
    "val train = splits(0)\n",
    "val test = splits(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Perceptron sigmoïde sans couches cachées\n",
    "\n",
    "Comme ce perceptron ne possède pas de couches cachées, il y a donc ici deux couches:\n",
    "\n",
    "- une en entrée comportant 39 neurones,\n",
    "- une en sortie comportant 7 neurones.\n",
    "\n",
    "En effet, comme vu précédement, $|C| = 7$, comme notre fonction $p(fv_i) \\rightarrow c$ nous fournit un résultat dans l'ensemble $C$, il y a donc bien 7 neurones en sortie de notre perceptron.\n",
    "De même, $|fv| = 39$, la couche d'entrée est donc composée de 39 neurones dont le signal d'entrée est respectivement est la valeur de $f$. Rappelons que $f_j \\in \\mathbb{B}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "// Les couches sont représentées par un vecteur d'entiers\n",
    "val layers = Array[Int](39, 7)\n",
    "\n",
    "// Création du perceptron\n",
    "// 100 itérations maximum \n",
    "\n",
    "val p = new MultilayerPerceptronClassifier() \n",
    "val trainer = p.setLayers(layers).setMaxIter(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Entrainement\n",
    "L'entrainement du perceptron se fait sur le dataset d'entrainement\n",
    "et non pas sur celui de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "val model = trainer.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Résultat\n",
    "On test le modèle sur le dataset de test afin de déterminer la pertinence du modèle. Il est important de ne pas tester le modèle sur les données d'entrainement pour ne pas biaiser les résultats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "Pertinence du modèle sans couches cachées: 0.4814310390645761\n"
     ]
    }
   ],
   "source": [
    "val result = model.transform(test)\n",
    "\n",
    "// extraction des données générées\n",
    "val predictionAndLabels = result.select(\"prediction\", \"label\")\n",
    "\n",
    "// On utilise un MulticlassClassificationEvaluator pour évaluer la pertinence\n",
    "val evaluator = new MulticlassClassificationEvaluator().setMetricName(\"accuracy\")\n",
    "\n",
    "println(\"Pertinence du modèle sans couches cachées: \" + evaluator.evaluate(predictionAndLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "On obtient donc une pertinence de 59,2%, c'est à dire que ce perceptron est capable de prédire un peu plus d'un crime sur deux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Voici une fonction générique permettant d'entrainer une perceptron :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def trainNN(layers : Array[Int],\n",
    "            train : Dataset[Row], test: Dataset[Row],\n",
    "            maxIter: Int)\n",
    " : Double = {\n",
    "\n",
    " // Création du perceptron\n",
    " val p = new MultilayerPerceptronClassifier() \n",
    " val trainer = p.setLayers(layers).setMaxIter(maxIter) \n",
    "  \n",
    " // Entrainement\n",
    " val model = trainer.fit(train)\n",
    " // Test de la pertinence de ce nouveau modèle\n",
    " val result = model.transform(test)\n",
    " // extraction des données générées\n",
    " val predictionAndLabels = result.select(\"prediction\", \"label\")\n",
    "\n",
    " // On utilise un MulticlassClassificationEvaluator pour évaluer la pertinence\n",
    " val evaluator = new MulticlassClassificationEvaluator().setMetricName(\"accuracy\")\n",
    "\n",
    " evaluator.evaluate(predictionAndLabels)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100;0.5923617822508082                                                          \n",
      "200;0.5926283867097677                                                          \n",
      "300;0.5924284333655481                                                          \n",
      "400;0.5916619455460392                                                          \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Name: java.lang.InterruptedException\n",
       "Message: null\n",
       "StackTrace:   at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1326)\n",
       "  at scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:208)\n",
       "  at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:218)\n",
       "  at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)\n",
       "  at scala.concurrent.Await$$anonfun$result$1.apply(package.scala:190)\n",
       "  at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)\n",
       "  at scala.concurrent.Await$.result(package.scala:190)\n",
       "  at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:81)\n",
       "  at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)\n",
       "  at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:78)\n",
       "  at org.apache.spark.storage.BlockManagerMaster.updateBlockInfo(BlockManagerMaster.scala:67)\n",
       "  at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$tryToReportBlockStatus(BlockManager.scala:363)\n",
       "  at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$reportBlockStatus(BlockManager.scala:342)\n",
       "  at org.apache.spark.storage.BlockManager$$anonfun$doPutBytes$1.apply(BlockManager.scala:811)\n",
       "  at org.apache.spark.storage.BlockManager$$anonfun$doPutBytes$1.apply(BlockManager.scala:763)\n",
       "  at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:866)\n",
       "  at org.apache.spark.storage.BlockManager.doPutBytes(BlockManager.scala:763)\n",
       "  at org.apache.spark.storage.BlockManager.putBytes(BlockManager.scala:742)\n",
       "  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$writeBlocks$1.apply(TorrentBroadcast.scala:111)\n",
       "  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$writeBlocks$1.apply(TorrentBroadcast.scala:108)\n",
       "  at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
       "  at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)\n",
       "  at org.apache.spark.broadcast.TorrentBroadcast.writeBlocks(TorrentBroadcast.scala:108)\n",
       "  at org.apache.spark.broadcast.TorrentBroadcast.<init>(TorrentBroadcast.scala:86)\n",
       "  at org.apache.spark.broadcast.TorrentBroadcastFactory.newBroadcast(TorrentBroadcastFactory.scala:34)\n",
       "  at org.apache.spark.broadcast.BroadcastManager.newBroadcast(BroadcastManager.scala:56)\n",
       "  at org.apache.spark.SparkContext.broadcast(SparkContext.scala:1387)\n",
       "  at org.apache.spark.mllib.optimization.LBFGS$CostFun.calculate(LBFGS.scala:246)\n",
       "  at org.apache.spark.mllib.optimization.LBFGS$CostFun.calculate(LBFGS.scala:235)\n",
       "  at breeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:23)\n",
       "  at breeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:41)\n",
       "  at breeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:30)\n",
       "  at breeze.optimize.StrongWolfeLineSearch.breeze$optimize$StrongWolfeLineSearch$$phi$1(StrongWolfe.scala:69)\n",
       "  at breeze.optimize.StrongWolfeLineSearch$$anonfun$minimize$1.apply$mcVI$sp(StrongWolfe.scala:142)\n",
       "  at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n",
       "  at breeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:141)\n",
       "  at breeze.optimize.LBFGS.determineStepSize(LBFGS.scala:77)\n",
       "  at breeze.optimize.LBFGS.determineStepSize(LBFGS.scala:40)\n",
       "  at breeze.optimize.FirstOrderMinimizer$$anonfun$infiniteIterations$1.apply(FirstOrderMinimizer.scala:117)\n",
       "  at breeze.optimize.FirstOrderMinimizer$$anonfun$infiniteIterations$1.apply(FirstOrderMinimizer.scala:115)\n",
       "  at scala.collection.Iterator$$anon$7.next(Iterator.scala:129)\n",
       "  at breeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:71)\n",
       "  at org.apache.spark.mllib.optimization.LBFGS$.runLBFGS(LBFGS.scala:212)\n",
       "  at org.apache.spark.mllib.optimization.LBFGS.optimize(LBFGS.scala:142)\n",
       "  at org.apache.spark.ml.ann.FeedForwardTrainer.train(Layer.scala:819)\n",
       "  at org.apache.spark.ml.classification.MultilayerPerceptronClassifier.train(MultilayerPerceptronClassifier.scala:262)\n",
       "  at org.apache.spark.ml.classification.MultilayerPerceptronClassifier.train(MultilayerPerceptronClassifier.scala:147)\n",
       "  at org.apache.spark.ml.Predictor.fit(Predictor.scala:90)\n",
       "  at trainNN(<console>:76)\n",
       "  at $anonfun$1.apply$mcVI$sp(<console>:78)\n",
       "  at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Création des couches\n",
    "\n",
    "(100 until 1000 by 100).foreach((nl)=>{ \n",
    " val layers = Array[Int](39,nl,7)\n",
    " println(nl + \";\" + trainNN(layers, train, test, 40))\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Perceptron sigmoïde avec une couche cachée\n",
    "\n",
    "Nous allons entrainer un autre réseau de neurones possédant cette fois ci une couche cachée.\n",
    "La règle est que le nombre de neurones $n$ de cette couche doit être $n \\le |fv|^2$, c'est-à-dire $n \\le 32^2 \\Leftrightarrow n \\le 1024 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "Pertinence du modèle avec une couche cachée: 0.592461758922918\n"
     ]
    }
   ],
   "source": [
    "// Création des couches\n",
    "val layers = Array[Int](39, 1024, 7)\n",
    "\n",
    "println(\"Pertinence du modèle avec une couche cachée: \" + trainNN(layers, train, test, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Perceptron sigmoïde avec deux couches cachées\n",
    "\n",
    "Nous allons enfin entrainer un dernier réseau de neurones possédant cette fois ci deux couche cachée. La couche d'entrée prends toujours 39 neurones, et celle de sortie 7 neurones. Nous avons choisi d'utiliser respectivement 512 et 256 neurones pour les première et seconde couches cachées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "Pertinence du modèle avec deux couches cachées: 0.591828573332889\n"
     ]
    }
   ],
   "source": [
    "// Création des couches\n",
    "val layers = Array[Int](39, 512, 256, 7)\n",
    "\n",
    "println(\"Pertinence du modèle avec deux couches cachées: \" + trainNN(layers, train, test, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Analyse critique\n",
    "\n",
    "Déterminer les paramètres optimaux pour obtenir la meilleur pertinance du modèle peut se faire soit mathématiquement soit empiriquement. Face à la complexitée de ces modèles nous avons choisi de déterminer les paramètres optimaux de façon empirique. Nos paramêtres sont:\n",
    "\n",
    "- $t$ : le nombre d'itérations maximum pour l'entrainement du perceptron (training),\n",
    "- $n_l$ : le nombre de neurones $n$ composants la couche $l$, la couche d'entrée étant $l=0$.\n",
    "\n",
    "Il est bon de noter que les couches d'entrée et de sortie ne peuvent pas changer, le nombre de features et de catégories à prédire étant fixes.\n",
    "\n",
    "Nous pouvons donc obtenir plusieurs mesures de la pertinance en fonction :\n",
    "\n",
    "- du nombre d'itérations, formant une courbe.\n",
    "- du nombre d'itérations et du nombre de neurones dans **une** couche, formant un plan,\n",
    "- du nombre d'itérations, du nombre de couches et du nombre de neuronnes dans chaque couches, formant un plan en plus de 3 dimentions.\n",
    "\n",
    "Nous avons commencé par \"jouer\" à la main avec les paramètres pour déterminer si leurs modification provoquait effectivement des changements de la pertinance du modèle. Nous avons donc modifié les paramètres de façon dichotomique pour obtenir un premier feeling de leur importance. Mais les résultats ne se sont pas du tout avérés correspondre à nos attentes. En effet, le perceptron sans couche cachée nous donne une pertinance d'environ $0.5924$, indiquant:\n",
    "\n",
    "- que les données ne sont pas linéairement séparables, sans quoi la pertinance serait bien plus proche de 1,\n",
    "- que les données, bien que n'étant pas linéairement séparables, sont néanmoins très réparties, c'est à dire qu'il est certainement possible de séparer linéairement des groupes de données. Cela résulte sans doute du prétraitement de nos données qui consistait à réduire les catégories en groupes de catégories.\n",
    "\n",
    "Nous avons remarqué que le nombre d'itérations maximum $t$ influait sur la pertinance du modèle, mais celà est une évidence pour un perceptron et ne nous apprend rien de bien utile. Voici néanmoins un graphique représentant la pertinance en fonction de $t$:\n",
    "\n",
    "![Pertinance en fonction de t](img/t.png \"Pertinance en fonction de $t$\")\n",
    "\n",
    "Nous avons donc déterminé qu'il était inutile d'entrainer le perceptron avec $ t > 40$.\n",
    "\n",
    "Nous avons été néanmoins beaucoup plus surpris que l'ajout de couches cachées n'améliore pas la pertinance.\n",
    "L'ajout de couches cachées permets en théorie de faire émerger l'intelligence du réseau de neurone, mais dans notre cas, l'ajout de la couche cachée n'a en rien amélioré la pertinance du modèle. Nous avons testé si $t = 40$ était toujours pertinant avec une couche cachée à chaques entrainement et c'est bien le cas. Voici la pertinance du modèle en fonction de $n_1$ pour $t = 40$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
